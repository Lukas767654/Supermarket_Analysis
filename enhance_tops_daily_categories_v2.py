#!/usr/bin/env python3
"""
Tops Daily Category Enhancement System
=====================================

Intelligent categorization enhancement using clustering methods and Gemini Flash AI
to properly categorize products currently labeled as "Other Products".

This system:
1. Analyzes product types in "Other Products"  
2. Uses clustering to group similar products
3. Employs Gemini Flash AI for intelligent categorization
4. Maps products to appropriate existing or new categories
5. Generates enhanced dataset with improved categorization

Based on the successful CJMore enhancement methodology.
"""

import pandas as pd
import numpy as np
from pathlib import Path
import google.generativeai as genai
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
import os
from dotenv import load_dotenv
from collections import Counter, defaultdict
import json
import time
import warnings
warnings.filterwarnings('ignore')

# Load environment variables
load_dotenv()

class TopsDaily_CategoryEnhancer:
    """Enhanced categorization system for Tops Daily products"""
    
    def __init__(self):
        """Initialize the category enhancement system"""
        
        # Configure Gemini AI
        api_key = os.getenv('GOOGLE_API_KEY')
        if not api_key:
            raise ValueError("GOOGLE_API_KEY not found in environment variables")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # File paths
        self.input_file = Path('tops_daily_analysis_output/csv_exports/tops_daily_brand_classification_enhanced.csv')
        self.output_dir = Path('tops_daily_analysis_output/csv_exports')
        self.output_file = self.output_dir / 'tops_daily_brand_classification_super_enhanced.csv'
        
        # Enhanced category mapping rules based on supermarket context
        self.category_mappings = {
            # Pet Care & Accessories
            'Pet Care & Accessories': [
                'Cat Food', 'Dog Food', 'Pet Food', 'Cat Treats', 'Dog Treats', 'Pet Treats',
                'Pet Accessories', 'Cat Litter', 'Dog Toy', 'Pet Toy', 'Fish Food', 'Bird Food'
            ],
            
            # Food & Beverages
            'Food & Beverages': [
                # Beverages
                'Beer', 'Wine', 'Alcohol', 'Juice', 'Soft Drink', 'Energy Drink', 'Water',
                'Coffee', 'Tea', 'Soda', 'Beverage', 'Drink',
                # Food items
                'Rice', 'Noodles', 'Pasta', 'Bread', 'Cereal', 'Snacks', 'Crackers',
                'Yogurt', 'Milk', 'Cheese', 'Frozen Food', 'Ice Cream', 'Candy', 'Chocolate',
                'Sauce', 'Oil', 'Spice', 'Seasoning', 'Soup', 'Instant', 'Canned'
            ],
            
            # Health & Personal Care  
            'Health & Personal Care': [
                'Mouthwash', 'Toothpaste', 'Shampoo', 'Soap', 'Skin care', 'Cosmetic',
                'Lotion', 'Perfume', 'Deodorant', 'Hair care', 'Body wash', 'Conditioner',
                'Face wash', 'Sunscreen', 'Moisturizer', 'Cream', 'Serum', 'Mask'
            ],
            
            # Household & Cleaning
            'Household & Cleaning': [
                'Detergent', 'Fabric Softener', 'Cleaning', 'Tissue', 'Paper',
                'Toilet paper', 'Kitchen towel', 'Napkin', 'Dishwash', 'Floor cleaner',
                'Glass cleaner', 'Disinfectant', 'Bleach', 'Air freshener'
            ],
            
            # Baby Care & Health
            'Baby Care & Health': [
                'Baby Food', 'Baby Formula', 'Diapers', 'Baby Care', 'Baby Powder',
                'Baby Shampoo', 'Baby Oil', 'Baby Wipes', 'Pacifier', 'Bottle'
            ],
            
            # Electronics & Accessories
            'Electronics & Accessories': [
                'Battery', 'Charger', 'Cable', 'Phone case', 'Headphone', 'Speaker',
                'Memory card', 'USB', 'Electronics', 'Gadget'
            ],
            
            # Home & Garden
            'Home & Garden': [
                'Plant', 'Flower', 'Pot', 'Garden', 'Tool', 'Light bulb', 'Candle',
                'Decoration', 'Storage', 'Container', 'Basket'
            ]
        }
        
        # Load existing data
        self.load_data()
        
        print("ðŸ¤– Tops Daily Category Enhancement System Initialized")
        print(f"ðŸ“Š Loaded {len(self.df):,} products")
        print(f"ðŸŽ¯ Target: {len(self.other_products):,} 'Other Products' ({self.other_percentage:.1f}%)")
    
    def load_data(self):
        """Load and prepare data for enhancement"""
        
        if not self.input_file.exists():
            raise FileNotFoundError(f"Input file not found: {self.input_file}")
        
        # Load main dataset
        self.df = pd.read_csv(self.input_file)
        
        # Identify "Other Products" for enhancement
        self.other_products = self.df[self.df['category'] == 'Other Products'].copy()
        self.other_percentage = (len(self.other_products) / len(self.df)) * 100
        
        # Get existing categories (excluding "Other Products")
        self.existing_categories = list(self.df[self.df['category'] != 'Other Products']['category'].unique())
        
        print(f"ðŸ“ˆ Enhancement scope: {len(self.other_products)} products to categorize")
    
    def analyze_product_types_clustering(self):
        """Use clustering to group similar product types"""
        
        print("\nðŸ”¬ Analyzing Product Types with Clustering...")
        
        if len(self.other_products) == 0:
            print("   âœ… No 'Other Products' to analyze!")
            return {}
        
        # Get product type descriptions for clustering
        product_descriptions = []
        product_indices = []
        
        for idx, row in self.other_products.iterrows():
            # Combine product_type and brand for better context
            description = f"{row['product_type']} {row['brand']}"
            product_descriptions.append(description.lower())
            product_indices.append(idx)
        
        if len(product_descriptions) < 2:
            print("   âš ï¸  Insufficient data for clustering")
            return {}
        
        # TF-IDF Vectorization
        vectorizer = TfidfVectorizer(
            max_features=100,
            stop_words='english',
            ngram_range=(1, 2),
            min_df=1
        )
        
        try:
            tfidf_matrix = vectorizer.fit_transform(product_descriptions)
            
            # Determine optimal number of clusters
            n_clusters = min(15, max(3, len(set(self.other_products['product_type'])) // 2))
            
            # K-means clustering
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            cluster_labels = kmeans.fit_predict(tfidf_matrix)
            
            # Analyze clusters
            clusters = defaultdict(list)
            for i, cluster_id in enumerate(cluster_labels):
                idx = product_indices[i]
                clusters[cluster_id].append({
                    'index': idx,
                    'product_type': self.other_products.loc[idx, 'product_type'],
                    'brand': self.other_products.loc[idx, 'brand']
                })
            
            print(f"   âœ… Created {len(clusters)} product clusters")
            
            # Analyze cluster quality
            cluster_analysis = {}
            for cluster_id, items in clusters.items():
                product_types = [item['product_type'] for item in items]
                most_common = Counter(product_types).most_common(3)
                
                cluster_analysis[cluster_id] = {
                    'size': len(items),
                    'items': items,
                    'top_types': most_common,
                    'coherence': most_common[0][1] / len(items) if most_common else 0
                }
            
            return cluster_analysis
            
        except Exception as e:
            print(f"   âŒ Clustering failed: {e}")
            return {}
    
    def rule_based_categorization(self, product_type, brand):
        """Apply enhanced rule-based categorization using predefined mappings"""
        
        product_type_lower = str(product_type).lower()
        brand_lower = str(brand).lower()
        combined_text = f"{product_type_lower} {brand_lower}"
        
        # Check direct category mappings
        for category_name, keywords in self.category_mappings.items():
            for keyword in keywords:
                if keyword.lower() in combined_text:
                    return category_name
        
        # Additional pattern matching for edge cases
        patterns = {
            'Food & Beverages': [
                'food', 'drink', 'beverage', 'milk', 'water', 'juice', 'coffee', 'tea',
                'snack', 'candy', 'chocolate', 'cookie', 'biscuit', 'cake', 'bread'
            ],
            'Health & Personal Care': [
                'health', 'care', 'beauty', 'hygiene', 'medical', 'vitamin', 'supplement',
                'oral', 'dental', 'skin', 'hair', 'body', 'face'
            ],
            'Household & Cleaning': [
                'clean', 'wash', 'home', 'kitchen', 'bathroom', 'laundry', 'polish',
                'fresh', 'household', 'domestic'
            ],
            'Pet Care & Accessories': [
                'pet', 'animal', 'dog', 'cat', 'fish', 'bird', 'veterinary'
            ]
        }
        
        for category, pattern_keywords in patterns.items():
            for keyword in pattern_keywords:
                if keyword in combined_text:
                    return category
        
        return None
    
    def gemini_categorization(self, products_batch):
        """Use Gemini Flash AI for intelligent categorization"""
        
        print(f"\nðŸ¤– Gemini AI Categorization (Batch of {len(products_batch)})...")
        
        # Prepare existing categories context
        existing_cats = ", ".join(self.existing_categories)
        
        # Create batch prompt
        products_text = "\n".join([
            f"- Product Type: {p['product_type']}, Brand: {p['brand']}"
            for p in products_batch
        ])
        
        prompt = f"""
You are a supermarket category expert analyzing products for Tops Daily supermarket in Thailand.

EXISTING CATEGORIES (use these when appropriate):
{existing_cats}

PRODUCTS TO CATEGORIZE:
{products_text}

INSTRUCTIONS:
1. For each product, suggest the MOST APPROPRIATE category
2. Use existing categories when possible
3. If none fit well, suggest a new logical category name
4. Consider Thai supermarket context and customer shopping patterns
5. Group similar products together

RESPONSE FORMAT (JSON):
{{
  "categorizations": [
    {{
      "product_type": "Beer",
      "brand": "Chang", 
      "suggested_category": "Food & Beverages",
      "confidence": "high",
      "reasoning": "Alcoholic beverages typically grouped with food in Thai supermarkets"
    }}
  ]
}}

Provide categorization for ALL {len(products_batch)} products."""

        try:
            response = self.model.generate_content(prompt)
            
            # Parse JSON response
            response_text = response.text.strip()
            
            # Extract JSON from response
            if '```json' in response_text:
                json_start = response_text.find('```json') + 7
                json_end = response_text.find('```', json_start)
                json_text = response_text[json_start:json_end].strip()
            else:
                json_text = response_text
            
            result = json.loads(json_text)
            
            print(f"   âœ… Gemini processed {len(result.get('categorizations', []))} products")
            return result.get('categorizations', [])
            
        except Exception as e:
            print(f"   âŒ Gemini categorization failed: {e}")
            return []
    
    def enhance_categories(self):
        """Main enhancement process combining clustering and AI"""
        
        print("\nðŸš€ Starting Category Enhancement Process...")
        print("=" * 60)
        
        if len(self.other_products) == 0:
            print("âœ… No enhancement needed - all products properly categorized!")
            return
        
        # Step 1: Rule-based categorization
        print("\nðŸ“‹ Step 1: Rule-Based Categorization...")
        rule_based_changes = 0
        
        for idx, row in self.other_products.iterrows():
            suggested_category = self.rule_based_categorization(row['product_type'], row['brand'])
            if suggested_category and suggested_category in self.existing_categories:
                self.df.loc[idx, 'category'] = suggested_category
                rule_based_changes += 1
        
        print(f"   âœ… Rule-based: {rule_based_changes} products categorized")
        
        # Update other_products after rule-based changes
        self.other_products = self.df[self.df['category'] == 'Other Products'].copy()
        
        # Step 2: Clustering analysis
        cluster_analysis = self.analyze_product_types_clustering()
        
        # Step 3: Gemini AI categorization for remaining products
        if len(self.other_products) > 0:
            print(f"\nðŸ¤– Step 2: AI-Powered Categorization...")
            
            # Process in batches for better API handling
            batch_size = 20
            ai_changes = 0
            
            products_for_ai = []
            for idx, row in self.other_products.iterrows():
                products_for_ai.append({
                    'index': idx,
                    'product_type': row['product_type'],
                    'brand': row['brand']
                })
            
            # Process batches
            for i in range(0, len(products_for_ai), batch_size):
                batch = products_for_ai[i:i + batch_size]
                
                # Get AI categorizations
                ai_results = self.gemini_categorization(batch)
                
                # Apply AI suggestions
                for j, product in enumerate(batch):
                    if j < len(ai_results):
                        ai_result = ai_results[j]
                        suggested_category = ai_result.get('suggested_category', 'Other Products')
                        confidence = ai_result.get('confidence', 'low')
                        
                        # Apply high-confidence suggestions
                        if confidence in ['high', 'medium']:
                            self.df.loc[product['index'], 'category'] = suggested_category
                            ai_changes += 1
                
                # Rate limiting
                time.sleep(1)
            
            print(f"   âœ… AI-powered: {ai_changes} products categorized")
        
        # Step 4: Generate enhancement report
        self.generate_enhancement_report(rule_based_changes, ai_changes, cluster_analysis)
    
    def generate_enhancement_report(self, rule_changes, ai_changes, clusters):
        """Generate comprehensive enhancement report"""
        
        # Calculate final statistics
        final_other_products = len(self.df[self.df['category'] == 'Other Products'])
        final_other_percentage = (final_other_products / len(self.df)) * 100
        
        total_improved = rule_changes + ai_changes
        improvement_percentage = ((len(self.other_products) - final_other_products) / len(self.other_products)) * 100 if len(self.other_products) > 0 else 0
        
        print("\n" + "=" * 60)
        print("ðŸ“Š CATEGORY ENHANCEMENT RESULTS")
        print("=" * 60)
        print(f"ðŸŽ¯ Initial 'Other Products': {len(self.other_products):,} (31.3%)")
        print(f"âœ… Final 'Other Products': {final_other_products:,} ({final_other_percentage:.1f}%)")
        print(f"ðŸ“ˆ Products Enhanced: {total_improved:,}")
        print(f"ðŸ† Improvement Rate: {improvement_percentage:.1f}%")
        print()
        print("Enhancement Breakdown:")
        print(f"  ðŸ“‹ Rule-based: {rule_changes:,} products")
        print(f"  ðŸ¤– AI-powered: {ai_changes:,} products")
        print()
        print("Category Distribution After Enhancement:")
        category_counts = self.df['category'].value_counts()
        for category, count in category_counts.head(10).items():
            percentage = (count / len(self.df)) * 100
            print(f"  {category}: {count:,} ({percentage:.1f}%)")
        
        if len(clusters) > 0:
            print(f"\nðŸ”¬ Clustering Analysis: {len(clusters)} coherent groups identified")
            for cluster_id, cluster_info in clusters.items():
                if cluster_info['coherence'] > 0.5 and cluster_info['size'] >= 3:
                    top_type = cluster_info['top_types'][0][0] if cluster_info['top_types'] else 'Mixed'
                    print(f"  Cluster {cluster_id}: {cluster_info['size']} items ({top_type})")
        
        print("=" * 60)
    
    def save_enhanced_dataset(self):
        """Save the enhanced dataset with improved categorization"""
        
        print(f"\nðŸ’¾ Saving Enhanced Dataset...")
        
        # Ensure output directory exists
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Add enhancement metadata
        self.df['enhancement_version'] = 'v2.0_super_enhanced'
        self.df['enhancement_timestamp'] = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # Save enhanced dataset
        self.df.to_csv(self.output_file, index=False)
        
        # Also update the original enhanced file
        original_enhanced = self.output_dir / 'tops_daily_brand_classification_enhanced.csv'
        self.df.to_csv(original_enhanced, index=False)
        
        print(f"   âœ… Saved: {self.output_file.name}")
        print(f"   âœ… Updated: {original_enhanced.name}")
        print(f"   ðŸ“Š Dataset: {len(self.df):,} products with enhanced categories")
    
    def run_complete_enhancement(self):
        """Execute the complete category enhancement process"""
        
        print("ðŸš€ TOPS DAILY CATEGORY ENHANCEMENT SYSTEM")
        print("=" * 60)
        print("ðŸŽ¯ Mission: Eliminate 'Other Products' through intelligent categorization")
        print("ðŸ¤– Technology: Rule-based + Clustering + Gemini Flash AI")
        print("ðŸ“Š Target: Achieve <15% 'Other Products' for business-ready analytics")
        print()
        
        # Run enhancement
        self.enhance_categories()
        
        # Save results  
        self.save_enhanced_dataset()
        
        print("\nðŸ† ENHANCEMENT COMPLETE!")
        print("âœ… Tops Daily now has significantly improved categorization")
        print("ðŸ“ˆ Ready for advanced business analytics and reporting")
        print("ðŸŽ¯ Enhanced dataset available for Excel exports and visualizations")

def main():
    """Main execution function"""
    
    try:
        # Create and run enhancement system
        enhancer = TopsDaily_CategoryEnhancer()
        enhancer.run_complete_enhancement()
        
    except Exception as e:
        print(f"âŒ Enhancement failed: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())